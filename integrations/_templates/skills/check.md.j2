{#- Full Analysis Workflow - the flagship Reality Check command -#}
{#- This is the comprehensive template that includes all methodology content -#}

The flagship Reality Check command for rigorous source analysis.

{% include "partials/prerequisites.md.j2" %}

## Workflow Steps

1. **Fetch** - Retrieve and parse source content
   - Primary: `WebFetch` for most URLs
   - Alternative: `curl -L -sS "URL" | rc-html-extract - --format json`
   - `rc-html-extract` returns structured `{title, published, text, headings, word_count}`
   - Use the extract tool when you need clean metadata or main text extraction
2. **Metadata** - Extract title, author, date, type, generate source-id
3. **Stage 1: Descriptive** - Neutral summary, key claims, argument structure
4. **Stage 2: Evaluative** - Evidence quality, fact-checking, disconfirming evidence
5. **Stage 3: Dialectical** - Steelman, counterarguments, synthesis
6. **Extract** - Format claims as YAML
7. **Register** - Add source and claims to database
8. **Validate** - Run integrity checks
9. **README** - Update data project analysis index
10. **Commit** - Stage and commit changes to data repo
11. **Push** - Push to remote
12. **Report** - Generate summary

---

## Multi-source Requests (Compare / Contrast)

If the prompt includes **multiple sources** (multiple URLs/repos/papers) or explicitly asks for **compare/contrast**, the expected workflow is:

1. Run this `{{ invocation_prefix }}check` workflow **once per source** (one `analysis/sources/<source-id>.md` per source)
2. Then run `{{ invocation_prefix }}synthesize` to write a single cross-source synthesis at `analysis/syntheses/<synth-id>.md`

The synthesis should link back to the relevant source analyses and resolve (or clearly frame) points of agreement and disagreement.

---

## Analysis Output Contract

Every analysis must produce a **human-auditable analysis** file at:
`PROJECT_ROOT/analysis/sources/<source-id>.md`

The analysis **must** include:

1. **Metadata** (Source ID, URL, author, date/type)
2. **Legends** (top-of-file quick reference)
3. **Three-stage analysis** (Stages 1-3)
4. **Claim tables with evidence + credence**
5. **Extracted claims artifact** (embedded YAML or separate file)

If an analysis lacks claim tables (IDs, evidence levels, credence) it is **not complete**.

### Multi-source Output

For multi-source requests, produce:
- **One** source analysis per source: `analysis/sources/<source-id>.md`
- **One** synthesis (if requested/needed): `analysis/syntheses/<synth-id>.md` (see `{{ invocation_prefix }}synthesize`)

### Required Elements

**Stage 1 (Descriptive)**:
- Source Metadata table
- Core Thesis (1-3 sentences)
- Key Claims table (with Verified? and Falsifiable By columns)
- Argument Structure diagram
- Theoretical Lineage
- Scope & Limitations

**Stage 2 (Evaluative)**:
- Key Factual Claims Verified (with Crux? column)
- Disconfirming Evidence Search
- Internal Tensions / Self-Contradictions
- Persuasion Techniques
- Unstated Assumptions
- Evidence Assessment
- Credence Assessment

**Stage 3 (Dialectical)**:
- Steelmanned Argument
- Strongest Counterarguments
- Supporting Theories (with source IDs)
- Contradicting Theories (with source IDs)
- Synthesis Notes
- Claims to Cross-Reference

**End**:
- Claim Summary table (all claims)
- Claims to Register (YAML)
- Credence in Analysis (0.0-1.0)

---

## Analysis Template

Use this structure for analysis documents:

```markdown
# Source Analysis: [Title]

{% include "partials/legends.md.j2" %}

## Metadata

| Field | Value |
|-------|-------|
| **Source ID** | [author-year-shorttitle] |
| **Title** | [extracted from source] |
| **Author(s)** | [name(s)] |
| **Date** | [YYYY-MM-DD or YYYY] |
| **Type** | [PAPER/ARTICLE/BLOG/REPORT/INTERVIEW/etc.] |
| **URL** | [source URL] |
| **Reliability** | [0.0-1.0] |
| **Rigor Level** | [SPITBALL/DRAFT/REVIEWED/CANONICAL] |

## Stage 1: Descriptive Analysis

### Core Thesis
[1-3 sentence summary of main argument]

{% include "tables/key-claims.md.j2" %}

{% include "sections/argument-structure.md.j2" %}

{% include "sections/theoretical-lineage.md.j2" %}

### Scope & Limitations
[What does this source attempt to explain? What does it explicitly not address?]

## Stage 2: Evaluative Analysis

### Internal Coherence
[Does the argument follow logically? Any contradictions?]

{% include "tables/factual-claims-verified.md.j2" %}

{% include "tables/disconfirming-evidence.md.j2" %}

{% include "tables/internal-tensions.md.j2" %}

{% include "tables/persuasion-techniques.md.j2" %}

{% include "tables/unstated-assumptions.md.j2" %}

### Evidence Assessment
[Quality and relevance of supporting evidence]

### Credence Assessment
- **Overall Credence**: [0.0-1.0]
- **Reasoning**: [why this level?]

## Stage 3: Dialectical Analysis

### Steelmanned Argument
[Strongest possible version of this position]

### Strongest Counterarguments
1. [Counter + source if available]
2. [Counter + source if available]

{% include "tables/supporting-contradicting.md.j2" %}

### Synthesis Notes
[How does this update our overall understanding?]

### Claims to Cross-Reference
[Which claims should be checked against other sources?]

---

{% include "tables/claim-summary.md.j2" %}

### Claims to Register

\`\`\`yaml
claims:
  - id: "DOMAIN-YYYY-NNN"
    text: "[Precise claim statement]"
    type: "[F/T/H/P/A/C/S/X]"
    domain: "[DOMAIN]"
    evidence_level: "E[1-6]"
    credence: 0.XX
    operationalization: "[How to test/measure this claim]"
    assumptions: ["..."]
    falsifiers: ["What would refute this"]
    source_ids: ["[source-id]"]
\`\`\`

{% include "sections/credence-assessment.md.j2" %}
```

---

{% include "partials/evidence-hierarchy.md.j2" %}

{% include "partials/claim-types.md.j2" %}

{% include "partials/domain-codes.md.j2" %}

{% include "partials/credence-calibration.md.j2" %}

---

{% include "partials/db-commands.md.j2" %}

---

## Update README (REQUIRED)

After registration and validation, update the data project's README.md:

### 1. Add Syntheses Table Entry (if created)

If you produced a synthesis document, add a row to the "Syntheses" table (kept **above** "Source Analyses"):

```markdown
| YYYY-MM-DD | [Topic](analysis/syntheses/<synth-id>.md) | `[DRAFT/REVIEWED]` | Brief summary |
```

Insert at the **top** of the table (below header row), keeping entries reverse-chronological.

### 2. Add Source Analyses Table Entry

**Edit `$PROJECT_ROOT/README.md` now.** Find the "Source Analyses" table and insert a new row:

```markdown
| YYYY-MM-DD | [Title](analysis/sources/<source-id>.md) | `[REVIEWED]` | Brief summary |
```

Insert at the **top** of the table (below header row), keeping entries reverse-chronological.

### 3. Update Stats Tables

Run the stats update script to refresh claim/source counts:

```bash
# From the realitycheck framework directory
scripts/update-readme-stats.sh "$PROJECT_ROOT"
# or: bash scripts/update-readme-stats.sh "$(dirname "$REALITYCHECK_DATA")"
```

This updates the "Current Status" and "Claim Domains" tables automatically.

---

## Commit and Push (REQUIRED)

**You MUST commit and push after every successful analysis.** This is not optional.

```bash
# From the data project root
cd "$(dirname "$REALITYCHECK_DATA")"

# Stage all changes
git add data/ analysis/ tracking/ README.md claims/ reference/

# Commit with descriptive message
git commit -m "data: add [source-id] - [brief description]"

# Push to remote
git push
```

**Do not stop until changes are committed and pushed.** The analysis is incomplete without version control.

---

## Continuation Mode

When using `--continue` on an existing analysis:

1. **Find existing analysis**: Look for `analysis/sources/[source-id].md`
2. **Read current state**: Load the existing analysis and registered claims
3. **Iterate, don't overwrite**: Add to the existing analysis rather than replacing it
4. **Focus areas**:
   - Extract claims that were skipped or noted as "TODO"
   - Deepen specific sections (more counterfactuals, stronger steelman)
   - Add evidence that was found after initial analysis
   - Address questions or gaps identified in the original pass
   - Cross-reference with newly added claims in the database
5. **Preserve content**: Append new sections, update claim counts, note what changed
